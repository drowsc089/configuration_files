#每次发送的事件数
 
pipeline.batch.size: 10000
 
#发送延时
 
pipeline.batch.delay: 10
 
#pipeline线程数，官方建议是等于CPU内核数
 
pipeline.workers: 6
 
#监视配置文件的改变，并且当配置文件被修改以后自动重新加载配置文件
 
config.reload.automatic: true
 
#为了检查配置文件是否改变，而拉去配置文件的频率。默认3秒
 
config.reload.interval: 60s
 
#数据持久化
queue.type: persisted
 
#队列存储路径；如果队列类型为persisted，则生效
path.queue: /data/ELK/logstash/data
 
#队列为持久化，单个队列大小
queue.page_capacity: 1024mb
 
#当启用持久化队列时，队列中未读事件的最大数量，0为不限制
queue.max_events: 0
 
#队列最大容量100G
queue.max_bytes: 102400mb
 
#在启用持久队列时强制执行检查点的最大数量,0为不限制
queue.checkpoint.acks: 1024
 
#在启用持久队列时强制执行检查点之前的最大数量的写入事件，0为不限制
queue.checkpoint.writes: 1024
 
#当启用持久队列时，在头页面上强制一个检查点的时间间隔，单位毫秒
queue.checkpoint.interval: 1000 
 
#绑定的主机ip地址
 
http.host: "192.168.193.157"
 
#绑定的服务端口
 
http.port: 9600
 
#启用logstash的x-pack监控，默认为禁用
 
xpack.monitoring.enabled: true
 
#传输logstash监控数据时候用于通过elasticsearch认证的账号
xpack.monitoring.elasticsearch.username: logstash_system
 
#传输logstash监控数据时候用于通过elasticsearch认证的账号密码，这里使用预先存储在密钥文件keystore中的变量LOGSTASH_PWD的值来代替
xpack.monitoring.elasticsearch.password: "${LOGSTASH_PWD}"
 
#将logstash的监控数据发送到所指定的elasticsearch集群中，也可以是单个es主机
xpack.monitoring.elasticsearch.hosts: ["http://192.168.193.154:9200","http://192.168.193.155:9200","http://192.168.193.156:9200"]
 
#logstash数据存储目录
 
path.data: /data/ELK/logstash/data 
 
#包含的子配置文件目录
path.config: /data/ELK/logstash/config/conf.d/*.conf
 
#logstash日志目录
path.logs: /data/ELK/logstash/logs